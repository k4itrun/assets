name: 'URL monitor'

on:
 schedule:
  - cron: '*/5 * * * *'
 workflow_dispatch:

env:
 MONITOR_URLS: ${{ secrets.MONITOR_URL }}
 MAX_RETRIES: 3
 RETRY_DELAY: 5
 ACCEPTED_STATUSES: '200,201,204,301,302'

jobs:
 url-monitor:
  runs-on: ubuntu-latest
  timeout-minutes: 5
  steps:
   - name: Split and Validate URLs
     id: prepare
     run: |
      if [ -z "$MONITOR_URLS" ]; then
        echo "::error::No URLs provided"
        exit 1
      fi

      echo "Received URLs:"
      echo "$MONITOR_URLS"

      echo "$MONITOR_URLS" | tr ',; ' '\n' | grep -v '^$' > urls.txt
      cat urls.txt

   - name: Check URLs
     id: check
     run: |
      ACCEPTED_CODES=$(echo "$ACCEPTED_STATUSES" | tr ',' '|')

      while IFS= read -r url; do
        echo "Checking: $url"
        ATTEMPT=1
        SUCCESS=false

        until [ $ATTEMPT -gt $MAX_RETRIES ] || [ $SUCCESS = true ]; do
          echo "Attempt $ATTEMPT..."
          RESPONSE=$(curl -sS -o /dev/null -w "%{http_code} %{time_total} %{size_download}" \
                   --connect-timeout 10 \
                   --max-time 15 \
                   "$url")

          read STATUS_CODE LATENCY RESPONSE_SIZE <<< "$RESPONSE"

          if [[ "$STATUS_CODE" =~ ^($ACCEPTED_CODES)$ ]]; then
            echo "$url is healthy (Status: $STATUS_CODE, Latency: ${LATENCY}s, Size: ${RESPONSE_SIZE}B)"
            SUCCESS=true
          else
            echo "::warning::$url failed (Status: ${STATUS_CODE:-timeout})"
            if [ $ATTEMPT -lt $MAX_RETRIES ]; then
              sleep $((RETRY_DELAY * ATTEMPT))
            fi
            ((ATTEMPT++))
          fi
        done

        if [ $SUCCESS = false ]; then
          echo "::error::All attempts failed for $url"
          FAILED_URLS+=("$url")
        fi

      done < urls.txt

      if [ ${#FAILED_URLS[@]} -ne 0 ]; then
        echo "Some URLs failed:"
        printf '%s\n' "${FAILED_URLS[@]}"
        exit 1
      fi
